{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from typing import Dict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('..')  # Add this line to include the directory above\n",
    "\n",
    "# Import Data Processing Utilities\n",
    "from utils.processing import (remove_blocklist_addresses,\n",
    "                              validate_dataframe_june_19,\n",
    "                              preprocess_data,\n",
    "                              add_tef_graduate_column,\n",
    "                              calculate_nft_weighted_sum,\n",
    "                              create_dict_for_equal_cweights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = pd.read_csv(\"../data/2024-06-19_nft_balances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"../data/2024-06-19_nft_balances.csv\"\n",
    "file_exists = os.path.exists(file_name)\n",
    "file_exists\n",
    "# Read the CSV file\n",
    "original_user_data = pd.read_csv(file_name)\n",
    "\n",
    "# Set the index of the DataFrame to be Id\n",
    "original_user_data.set_index('Id', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column tokenId 2 contains 1 values other than 0 or 1.\n",
      "Setting these values to be in (0, 1)\n"
     ]
    }
   ],
   "source": [
    "# Check to see that everything is valid, clean if not. \n",
    "user_data = validate_dataframe_june_19(original_user_data)\n",
    "\n",
    "#Remove blocklist addresses \n",
    "BLOCKLIST_ADDRESSES = [\"0xa55078f87ceDa4aC72380C639229014acD3D1F75\",\n",
    "\"0xc6837f9d06D95Fa90CF91A6Dd6bB8cb51bfcfc59\",\n",
    "\"0x4CF57d42B8aB8D7Bfa9Be1cdC35Ed84429cD2168\"]\n",
    "\n",
    "user_data = remove_blocklist_addresses(df = user_data, \n",
    "                                       blocklist = BLOCKLIST_ADDRESSES)\n",
    "\n",
    "# Preprocess data and add a tef_graduate column\n",
    "user_data = preprocess_data(df = user_data)\n",
    "user_data = add_tef_graduate_column(user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data.to_csv(\"../data/processed_2024-06-19_nft_balances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tokenId 1', 'tokenId 2', 'tokenId 3', 'tokenId 4', 'tokenId 5',\n",
       "       'tokenId 6', 'tokenId 7', 'tokenId 8', 'tokenId 9', 'tokenId 10',\n",
       "       'tokenId 11', 'tokenId 12', 'tokenId 13', 'tokenId 14', 'tokenId 15',\n",
       "       'tokenId 16', 'tokenId 17', 'tokenId 18', 'tokenId 19', 'tokenId 20',\n",
       "       'tokenId 21', 'tokenId 22', 'tokenId 23', 'tokenId 24', 'tokenId 25',\n",
       "       'tokenId 26', 'tokenId 27', 'tokenId 28', 'tokenId 29', 'tokenId 30',\n",
       "       'tokenId 31', 'tokenId 32', 'tokenId 33', 'tokenId 34', 'tokenId 35',\n",
       "       'tokenId 36', 'tokenId 37', 'tokenId 38', 'tokenId 39', 'tokenId 40',\n",
       "       'tokenId 41', 'tokenId 42', 'tokenId 43', 'tokenId 44', 'tokenId 45',\n",
       "       'tef_graduate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating An Initial Weights Dictionary\n",
    "\n",
    "The dictionary below gives initial default weights for all attributes that a wallet could have.\n",
    "\n",
    "**Note:** Some attributes are set to 0, as a safety check on accidentally counting attributes that no user should have after processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_weights_dict = {\n",
    "    \"tokenId 1\": 7,   # Token ID 1\n",
    "    \"tokenId 2\": 0,   # Token ID 2\n",
    "    \"tokenId 3\": 7,   # Token ID 3\n",
    "    \"tokenId 4\": 0,   # Token ID 4\n",
    "    \"tokenId 5\": 7,   # Token ID 5\n",
    "    \"tokenId 6\": 0,   # Token ID 6\n",
    "    \"tokenId 7\": 7,   # Token ID 7\n",
    "    \"tokenId 8\": 0,   # Token ID 8\n",
    "    \"tokenId 9\": 7,   # Token ID 9\n",
    "    \"tokenId 10\": 0,  # Token ID 10\n",
    "    \"tokenId 11\": 20, # Token ID 11\n",
    "    \"tokenId 12\": 10, # Token ID 12\n",
    "    \"tokenId 13\": 10, # Token ID 13\n",
    "    \"tokenId 14\": 10, # Token ID 14\n",
    "    \"tokenId 15\": 16, # Token ID 15\n",
    "    \"tokenId 16\": 1,  # Token ID 16\n",
    "    \"tokenId 17\": 16, # Token ID 17\n",
    "    \"tokenId 18\": 5,  # Token ID 18\n",
    "    \"tokenId 19\": 1,  # Token ID 19\n",
    "    \"tokenId 20\": 3,  # Token ID 20\n",
    "    \"tokenId 21\": 3,  # Token ID 21\n",
    "    \"tokenId 22\": 1,  # Token ID 22\n",
    "    \"tokenId 23\": 10, # Token ID 23\n",
    "    \"tokenId 24\": 10, # Token ID 24\n",
    "    \"tokenId 25\": 10, # Token ID 25\n",
    "    \"tokenId 26\": 10, # Token ID 26\n",
    "    \"tokenId 27\": 10, # Token ID 27\n",
    "    \"tokenId 28\": 10, # Token ID 28\n",
    "    \"tokenId 29\": 10, # Token ID 29\n",
    "    \"tokenId 30\": 10, # Token ID 30\n",
    "    \"tokenId 31\": 15, # Token ID 31\n",
    "    \"tokenId 32\": 15, # Token ID 32\n",
    "    \"tokenId 33\": 15, # Token ID 33\n",
    "    \"tokenId 34\": 15, # Token ID 34\n",
    "    \"tokenId 35\": 15, # Token ID 35\n",
    "    \"tokenId 36\": 15, # Token ID 36\n",
    "    \"tokenId 37\": 15, # Token ID 37\n",
    "    \"tokenId 38\": 15, # Token ID 38\n",
    "    \"tokenId 39\": 18, # Token ID 39\n",
    "    \"tokenId 40\": 1,  # Token ID 40\n",
    "    \"tokenId 41\": 4, # Token ID 41\n",
    "    \"tokenId 42\": 18, # Token ID 42\n",
    "    \"tokenId 43\": 16,  # Token ID 43\n",
    "    \"tokenId 44\": 1,  # Token ID 44,\n",
    "    \"tokenId 45\": 10, # Token ID 45,\n",
    "    \"tef_graduate\": 0, #will be set in a moment\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_tokenIds = [f\"tokenId {num}\" for num in [11, 15, 17, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45]]\n",
    "graduate_tokenIds = [f\"tokenId {num}\" for num in  [1,2,3,4,5,6,7,8,9,10]]\n",
    "student_tokenIds = [f\"tokenId {num}\" for num in [12, 13, 14, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original total cweight is: 9382.\n",
      "The original expert cweight is: 708.\n",
      "The original graduate cweight is: 3850.\n",
      "The total TEF tokenIDs weight (for passing all five TEF modules): is 35.\n",
      "There are 110 TEF graduates.\n",
      "The original student cweight is: 4824.\n",
      "Original student cweight is greater than original graduate cweight.\n",
      "Scaling graduate cweight.\n",
      "The TEF graduate boost to make the two cweights equal is: 8.854545454545452.\n",
      "After calculation, final student cweight should be: 4824.\n",
      "After calculation, final graduate cweight should be: 4824.0.\n",
      "The columns of this new TEF graduate df are: \n",
      "\n",
      "tokenId 1\n",
      "tokenId 2\n",
      "tokenId 3\n",
      "tokenId 4\n",
      "tokenId 5\n",
      "tokenId 6\n",
      "tokenId 7\n",
      "tokenId 8\n",
      "tokenId 9\n",
      "tokenId 10\n",
      "tef_graduate\n",
      "There are 110 graduates in this DataFrame.\n",
      "The weight of TEF graduate is: 8.854545454545452\n",
      "\n",
      " Final Check: \n",
      "\n",
      "Actual final total cweight is 14472.000000000002.\n",
      "Actual final expert cweight is 4824.0.\n",
      "Actual final graduate cweight is 4824.0.\n",
      "Actual final student cweight is: 4824.000000000002.\n"
     ]
    }
   ],
   "source": [
    "modified_weights_dict = create_dict_for_equal_cweights(df = user_data,\n",
    "                                                       original_weights_dict = default_weights_dict,\n",
    "                                                       expert_tokenIds_list = expert_tokenIds,\n",
    "                                                       graduate_tokenIds_list= graduate_tokenIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the modified_weights_dict to a DataFrame\n",
    "modified_weights_df = pd.DataFrame.from_dict(modified_weights_dict, orient='index', columns=['Weight']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenId 1</th>\n",
       "      <th>tokenId 2</th>\n",
       "      <th>tokenId 3</th>\n",
       "      <th>tokenId 4</th>\n",
       "      <th>tokenId 5</th>\n",
       "      <th>tokenId 6</th>\n",
       "      <th>tokenId 7</th>\n",
       "      <th>tokenId 8</th>\n",
       "      <th>tokenId 9</th>\n",
       "      <th>tokenId 10</th>\n",
       "      <th>...</th>\n",
       "      <th>tokenId 37</th>\n",
       "      <th>tokenId 38</th>\n",
       "      <th>tokenId 39</th>\n",
       "      <th>tokenId 40</th>\n",
       "      <th>tokenId 41</th>\n",
       "      <th>tokenId 42</th>\n",
       "      <th>tokenId 43</th>\n",
       "      <th>tokenId 44</th>\n",
       "      <th>tokenId 45</th>\n",
       "      <th>tef_graduate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>102.20339</td>\n",
       "      <td>102.20339</td>\n",
       "      <td>122.644068</td>\n",
       "      <td>6.813559</td>\n",
       "      <td>27.254237</td>\n",
       "      <td>122.644068</td>\n",
       "      <td>109.016949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.135593</td>\n",
       "      <td>8.854545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tokenId 1  tokenId 2  tokenId 3  tokenId 4  tokenId 5  tokenId 6  \\\n",
       "Weight        7.0        0.0        7.0        0.0        7.0        0.0   \n",
       "\n",
       "        tokenId 7  tokenId 8  tokenId 9  tokenId 10  ...  tokenId 37  \\\n",
       "Weight        7.0        0.0        7.0         0.0  ...   102.20339   \n",
       "\n",
       "        tokenId 38  tokenId 39  tokenId 40  tokenId 41  tokenId 42  \\\n",
       "Weight   102.20339  122.644068    6.813559   27.254237  122.644068   \n",
       "\n",
       "        tokenId 43  tokenId 44  tokenId 45  tef_graduate  \n",
       "Weight  109.016949         1.0   68.135593      8.854545  \n",
       "\n",
       "[1 rows x 46 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_weights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_weights_df.to_csv(\"../data/2024-06-19_modified_weights_dict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
